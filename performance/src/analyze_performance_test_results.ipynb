{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"perf_tests.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyML2kzbZETK++n6Aj2hFGDb"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YDnXMsfuGG2L","colab_type":"text"},"source":["Authenticate"]},{"cell_type":"code","metadata":{"id":"MvXxXBUNGGMI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594625297467,"user_tz":-120,"elapsed":14839,"user":{"displayName":"Kamil Olszewski","photoUrl":"","userId":"11407310702921568773"}}},"source":["from google.colab import auth\n","auth.authenticate_user()"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"24RlTBdz5J6k","colab_type":"text"},"source":["Methods for processing data\n","\n","CONFIGURATION_COLUMNS_DEFAULT_VALUES is a dict where keys are columns defining the performance test configuration and values are their default values (if any is defined). The default values are dedicated for configuration columns which were added at a later point and are missing from older test attempts.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"4YyZ89pKSlMh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594646141937,"user_tz":-120,"elapsed":2510,"user":{"displayName":"Kamil Olszewski","photoUrl":"","userId":"11407310702921568773"}}},"source":["import json\n","import warnings\n","from typing import Dict, List, Optional, Set, Tuple\n","\n","import numpy as np\n","import pandas as pd\n","from google.cloud import bigquery\n","from tabulate import tabulate\n","\n","\n","PREFIX_LABEL_INDICATOR = \"_prefix\"\n","PRECISION = 4\n","\n","# we assume here that configuration column value can only be missing\n","# if that column did not exist at the time of the test attempt\n","CONFIGURATION_COLUMNS_DEFAULT_VALUES = {\n","    \"composer_version\": None,\n","    \"airflow_version\": None,\n","    \"python_version\": None,\n","    \"environment_size\": None,\n","    \"elastic_dag_configuration_type\": None,\n","    \"private_ip_enabled\": None,\n","    \"drs_enabled\": False,\n","    \"AIRFLOW__CORE__STORE_SERIALIZED_DAGS\": False,\n","}\n","\n","\n","def assign_time_series_metrics(\n","    resources_dict: Dict, time_series_metrics: Set[str]\n",") -> None:\n","    \"\"\"\n","    Assigns time series metrics to proper resource type and metric category\n","\n","    :param resources_dict: dict containing information about analyzed resource types.\n","    :type resources_dict: Dict\n","    :param time_series_metrics: set of column names containing time series metrics data.\n","    :type time_series_metrics: Set[str]\n","    \"\"\"\n","\n","    for resource_type in resources_dict:\n","        resources_dict[resource_type][\"gauge_metrics\"] = []\n","        resources_dict[resource_type][\"cumulative_metrics\"] = []\n","\n","    # by iterating this way we make sure every metric ends up in only one of the resource types\n","    # and metric kinds\n","    for metric in time_series_metrics:\n","\n","        metric_elements = metric.split(\"__\")\n","        assigned = False\n","\n","        for resource_type in sorted(resources_dict):\n","\n","            if resource_type not in metric_elements:\n","                continue\n","\n","            if \"CUMULATIVE\" in metric_elements:\n","                resources_dict[resource_type][\"cumulative_metrics\"].append(metric)\n","                assigned = True\n","                break\n","\n","            if \"GAUGE\" in metric_elements:\n","                resources_dict[resource_type][\"gauge_metrics\"].append(metric)\n","                assigned = True\n","                break\n","\n","        if not assigned:\n","            warnings.warn(\n","                f\"Metric {metric} does not match any of resource types or metric kinds.\"\n","            )\n","\n","\n","def compare_performance_of_two_configurations(\n","    all_perf_test_data: pd.DataFrame,\n","    resources_dict: Dict,\n","    general_metrics: Set[str],\n","    env_conf_1: Dict,\n","    env_conf_2: Dict,\n","    include_test_attempts_with_failed_dag_runs: Optional[bool] = False,\n",") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n","    \"\"\"\n","    Collects results for test attempts matching two different configurations,\n","    calculates average values of metrics specified in resources_dict\n","    and returns a dataframe with comparison of these averages.\n","\n","    :param all_perf_test_data: pandas Dataframe with all performance test data collected from BQ.\n","    :type all_perf_test_data: pd.DataFrame\n","    :param resources_dict: dict containing information about time series metrics that should be\n","        analyzed for different resource types and optional filter that control resource aggregation.\n","    :type resources_dict: Dict\n","    :param general_metrics: set with metrics referring to a whole test attempt. Average of each of\n","        these metrics will be calculated across all matching test attempts.\n","    :type general_metrics: Set[str]\n","    :param env_conf_1: dict with configuration column values for first environment. If one of the\n","        configuration columns is missing, then all its values apply.\n","    :type env_conf_1: Dict\n","    :param env_conf_2: dict with configuration column values for second environment. Performance of\n","        this configuration will be compared in regard to configuration from env_conf_1.\n","    :type env_conf_2: Dict\n","    :param include_test_attempts_with_failed_dag_runs: set to True if you want the test attempts\n","        with failed dag runs to be included in analysis.\n","    :type include_test_attempts_with_failed_dag_runs: bool\n","\n","    :return: three pandas DataFrames:\n","        first: containing average values of general and time series metrics for both\n","            configurations as well as percentage difference between env_conf_2 and env_conf_1.\n","        second: containing number of test_attempts per set of configuration columns missing from\n","            env_conf_1. None of none of configuration columns are missing from env_conf_1.\n","        third: containing number of test_attempts per set of configuration columns missing from\n","            env_conf_2. None of none of configuration columns are missing from env_conf_2.\n","    :rtype: Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]\n","    \"\"\"\n","\n","    missing_conf_columns_1, missing_conf_columns_2 = validate_configurations(\n","        env_conf_1, env_conf_2\n","    )\n","\n","    # TODO: with column missing from ENVIRONMENT_CONFIGURATION make a total summary and a grouping\n","    #  (per every value of missing column)\n","    #  -> make it an option - either collect all matching or do the grouping;\n","    #  when doing the grouping, the groups should be chosen so that configurations\n","    #  differ only with one column - this difference in one column should be checked\n","    #  before doing the grouping on missing columns\n","\n","    configuration_data = collect_results_for_configuration(\n","        all_perf_test_data, env_conf_1, include_test_attempts_with_failed_dag_runs\n","    )\n","\n","    test_attempts_per_missing_conf_1 = (\n","        get_test_attempts_count_for_missing_conf_columns(\n","            configuration_data, missing_conf_columns_1\n","        )\n","        if missing_conf_columns_1\n","        else None\n","    )\n","\n","    _, conf_1_total_results = calculate_statistics_for_configuration(\n","        configuration_data, resources_dict, general_metrics\n","    )\n","\n","    configuration_data = collect_results_for_configuration(\n","        all_perf_test_data, env_conf_2, include_test_attempts_with_failed_dag_runs\n","    )\n","\n","    test_attempts_per_missing_conf_2 = (\n","        get_test_attempts_count_for_missing_conf_columns(\n","            configuration_data, missing_conf_columns_2\n","        )\n","        if missing_conf_columns_2\n","        else None\n","    )\n","\n","    _, conf_2_total_results = calculate_statistics_for_configuration(\n","        configuration_data, resources_dict, general_metrics\n","    )\n","\n","    categories = []\n","    conf_1_values = []\n","    conf_2_values = []\n","    differences = []\n","\n","    all_categories = set(conf_2_total_results).union(set(conf_1_total_results))\n","\n","    for category in sorted(all_categories):\n","\n","        if category not in conf_1_total_results or category not in conf_2_total_results:\n","\n","            conf_1_value = round(conf_1_total_results.get(category, np.nan), PRECISION)\n","            conf_2_value = round(conf_2_total_results.get(category, np.nan), PRECISION)\n","            # display nan in difference in case of category missing from one configuration\n","            percentage_change_str = np.nan\n","\n","        else:\n","            # it should be impossible for categories present for both configurations to be np.nan\n","            conf_1_value = round(conf_1_total_results[category], PRECISION)\n","            conf_2_value = round(conf_2_total_results[category], PRECISION)\n","\n","            # also covers the case when they are both zero\n","            if conf_1_value == conf_2_value:\n","                percentage_change_str = \"0.0%\"\n","            # if the first value is zero\n","            elif not conf_1_value:\n","                percentage_change_str = \"+inf\" if conf_2_value > 0 else \"-inf\"\n","            else:\n","                percentage_change = round(\n","                    abs((conf_2_value - conf_1_value) / conf_1_value * 100), PRECISION\n","                )\n","                change_sign = \"+\" if conf_2_value > conf_1_value else \"-\"\n","                percentage_change_str = f\"{change_sign}{percentage_change}%\"\n","\n","        categories.append(category)\n","        conf_1_values.append(conf_1_value)\n","        conf_2_values.append(conf_2_value)\n","        differences.append(percentage_change_str)\n","\n","    comparison_df = pd.DataFrame(\n","        {\n","            \"category\": categories,\n","            \"configuration_1\": conf_1_values,\n","            \"configuration_2\": conf_2_values,\n","            \"difference\": differences,\n","        }\n","    )\n","\n","    return (\n","        comparison_df,\n","        test_attempts_per_missing_conf_1,\n","        test_attempts_per_missing_conf_2,\n","    )\n","\n","\n","def validate_configurations(\n","    env_conf_1: Dict, env_conf_2: Dict\n",") -> Tuple[List[str], List[str]]:\n","    \"\"\"\n","    Checks the configuration that are to be compared and reports discrepancies.\n","\n","    :param env_conf_1: dict with configuration column values for first environment..\n","    :type env_conf_1: Dict\n","    :param env_conf_2: dict with configuration column values for second environment..\n","    :type env_conf_2: Dict\n","\n","    :return: two lists of configuration columns missing from both of configuration dicts.\n","    :rtype: Tuple[List[str], List[str]]\n","    \"\"\"\n","    missing_conf_columns_1 = check_configuration(env_conf_1, 1)\n","    missing_conf_columns_2 = check_configuration(env_conf_2, 2)\n","\n","    if env_conf_1 == env_conf_2:\n","        warnings.warn(\"Configurations are identical.\")\n","\n","    else:\n","\n","        missing_columns = env_conf_1.keys() - env_conf_2.keys()\n","        if missing_columns:\n","            warnings.warn(\n","                f\"Configuration 1 contains columns missing from configuration 2: {missing_columns}.\"\n","            )\n","\n","        missing_columns = env_conf_2.keys() - env_conf_1.keys()\n","        if missing_columns:\n","            warnings.warn(\n","                f\"Configuration 2 contains columns missing from configuration 1: {missing_columns}.\"\n","            )\n","\n","        # they should differ with only one configuration column:\n","        # - composer_version\n","        # - airflow version (if composer_version is set to None\n","        #   which indicates vanilla airflow tests)\n","        different_columns = {\n","            column\n","            for column in env_conf_1\n","            if column in env_conf_2 and env_conf_1[column] != env_conf_2[column]\n","        }\n","\n","        if len(different_columns) > 1:\n","            warnings.warn(\n","                f\"Configurations differ in more than one column: {different_columns}.\"\n","            )\n","\n","    return missing_conf_columns_1, missing_conf_columns_2\n","\n","\n","def check_configuration(env_conf: Dict, number: Optional[int] = None) -> List[str]:\n","    \"\"\"\n","    Checks if there are discrepancies in the environments configuration that should be\n","    collected for performance analysis.\n","\n","    :param env_conf: dict with configuration column values.\n","    :type env_conf: Dict\n","    :param number: optional number identifying the configuration.\n","    :type number: int\n","\n","    :return: list with configuration columns missing from given configuration.\n","    :rtype: List[str]\n","    \"\"\"\n","\n","    missing_conf_columns = list(\n","        sorted(CONFIGURATION_COLUMNS_DEFAULT_VALUES.keys() - env_conf.keys())\n","    )\n","\n","    for column in env_conf:\n","\n","        if column not in CONFIGURATION_COLUMNS_DEFAULT_VALUES:\n","            warnings.warn(\n","                f\"Configuration {number if number is not None else ''} contains column '{column}' \"\n","                f\"which is not a configuration column.\"\n","            )\n","\n","    if \"composer_version\" not in env_conf:\n","        warnings.warn(\n","            f\"composer_version column is missing \"\n","            f\"from configuration {number if number is not None else ''}.\"\n","        )\n","\n","    return missing_conf_columns\n","\n","\n","def collect_results_for_configuration(\n","    all_perf_test_data: pd.DataFrame,\n","    env_conf: Dict,\n","    include_test_attempts_with_failed_dag_runs: Optional[bool] = False,\n",") -> pd.DataFrame:\n","    \"\"\"\n","    Collects results matching configuration columns provided in env_conf dictionary.\n","\n","    :param all_perf_test_data: pandas Dataframe with all performance test data collected from BQ.\n","    :type all_perf_test_data: pd.DataFrame\n","    :param env_conf: dict with configuration column values. If one of the configuration columns\n","        is missing from the dictionary, then it is not included in query and all its values apply.\n","    :type env_conf: Dict\n","    :param include_test_attempts_with_failed_dag_runs: set to True if you want the test attempts\n","        with failed dag runs to be included in analysis.\n","    :type include_test_attempts_with_failed_dag_runs: bool\n","\n","    :return: pandas DataFrame containing performance metrics for test attempts that match the\n","        provided configuration.\n","    :rtype: pd.DataFrame\n","    \"\"\"\n","\n","    query_parts = []\n","\n","    for column_name, column_value in env_conf.items():\n","\n","        if isinstance(column_value, str):\n","            query_parts.append(f'{column_name} == \"{column_value}\"')\n","        else:\n","            query_parts.append(f\"{column_name} == {column_value}\")\n","\n","    if not include_test_attempts_with_failed_dag_runs:\n","        query_parts.append(\"dag_run_failed_count == 0\")\n","\n","    query = \" & \".join(query_parts)\n","\n","    return all_perf_test_data.query(query)\n","\n","\n","def get_test_attempts_count_for_missing_conf_columns(\n","    configuration_data: pd.DataFrame, missing_conf_columns: List[str]\n",") -> Optional[pd.DataFrame]:\n","    \"\"\"\n","    For provided subset of test attempts checks how many of them belong to different set of values\n","    of missing_conf_columns.\n","\n","    :param configuration_data: pandas DataFrame containing performance metrics for test attempts\n","        that match certain configuration dict.\n","    :type configuration_data: pd.DataFrame\n","    :param: missing_conf_columns: list with configuration columns missing from configuration dict.\n","    :type missing_conf_columns: List[str]\n","\n","    :return: pandas DataFrame that for every group of values of missing_conf_columns present in\n","        configuration_data contains number of test_attempts representing this group\n","    :rtype: pd.DataFrame\n","    \"\"\"\n","\n","    if not missing_conf_columns:\n","        warnings.warn(\"missing_conf_columns is empty.\")\n","        return None\n","\n","    df_rows = []\n","\n","    for group_name, group in configuration_data.groupby(missing_conf_columns):\n","\n","        test_attempts_in_group = len(group.groupby(\"uuid\"))\n","        missing_conf_columns_values = list(group_name)\n","\n","        df_rows.append(missing_conf_columns_values + [test_attempts_in_group])\n","\n","    test_attempts_per_missing_conf = pd.DataFrame(\n","        df_rows, columns=missing_conf_columns + [\"test_attempts\"]\n","    )\n","\n","    return test_attempts_per_missing_conf\n","\n","\n","def calculate_statistics_for_configuration(\n","    configuration_data: pd.DataFrame, resources_dict: Dict, general_metrics: Set[str]\n",") -> Tuple[Dict, Dict]:\n","    \"\"\"\n","    For provided subset of test attempts calculates average growth of cumulative metrics\n","    and average values of gauge and general metrics, grouping resources based on resource types and\n","    filters from resources_dict.\n","\n","    :param configuration_data: pandas DataFrame containing performance metrics for test attempts\n","        that match certain configuration.\n","    :type configuration_data: pd.DataFrame\n","    :param resources_dict: dict containing information about time series metrics that should be\n","        analyzed for different resource types and optional filter that control resource aggregation.\n","    :type resources_dict: Dict\n","    :param general_metrics: set with metrics referring to a whole test attempt. Average of each of\n","        these metrics will be calculated across all test attempts from configuration_data.\n","    :type general_metrics: Set[str]\n","\n","    :return: pandas DataFrame containing average values of general and time series metrics for both\n","        configurations as well as percentage difference between env_conf_2 and env_conf_1.\n","    :rtype: pd.DataFrame\n","    \"\"\"\n","\n","    uuid_results_dict = {}\n","\n","    for resource_type in resources_dict:\n","\n","        analyzed_columns = (\n","            resources_dict[resource_type][\"group_by_columns\"]\n","            + [\"timestamp\"]\n","            + resources_dict[resource_type][\"cumulative_metrics\"]\n","            + resources_dict[resource_type][\"gauge_metrics\"]\n","        )\n","\n","        configuration_data_grouped = configuration_data[analyzed_columns].groupby(\n","            resources_dict[resource_type][\"group_by_columns\"]\n","        )\n","\n","        uuid_index = resources_dict[resource_type][\"group_by_columns\"].index(\"uuid\")\n","\n","        group_filters = resources_dict[resource_type].get(\"group_filters\")\n","\n","        for group_name, single_resource_data in configuration_data_grouped:\n","\n","            if group_filters:\n","                group_filter_name = check_if_group_filters_apply(\n","                    group_name,\n","                    group_filters,\n","                    resources_dict[resource_type][\"group_by_columns\"],\n","                )\n","                if group_filter_name is None:\n","                    continue\n","            else:\n","                group_filter_name = \"all\"\n","\n","            uuid = group_name[uuid_index]\n","\n","            if uuid not in uuid_results_dict:\n","                uuid_results_dict[uuid] = {}\n","\n","            if group_filter_name not in uuid_results_dict[uuid]:\n","                uuid_results_dict[uuid][group_filter_name] = {}\n","\n","            # in case of pod metrics it is possible to get duplicated entries\n","            # due to multiple containers on given pod, but with a correct\n","            # subset of columns we can simply remove duplicated rows;\n","            # after removing duplicates we should have a single row per\n","            # timestamp in every group\n","            single_resource_data = single_resource_data.sort_values(\n","                [\"timestamp\"]\n","            ).drop_duplicates()\n","\n","            for cumulative_metric in resources_dict[resource_type][\n","                \"cumulative_metrics\"\n","            ]:\n","                # add _per_second suffix to cumulative metric names\n","                # to indicate the change in their meaning\n","                cumulative_metric_growth = f\"{cumulative_metric}_per_second\"\n","\n","                if (\n","                    cumulative_metric_growth\n","                    not in uuid_results_dict[uuid][group_filter_name]\n","                ):\n","                    uuid_results_dict[uuid][group_filter_name][\n","                        cumulative_metric_growth\n","                    ] = []\n","\n","                average_growth = process_cumulative_metric_for_single_resource(\n","                    single_resource_data,\n","                    cumulative_metric,\n","                    resources_dict[resource_type][\"group_by_columns\"],\n","                )\n","\n","                uuid_results_dict[uuid][group_filter_name][\n","                    cumulative_metric_growth\n","                ].append(average_growth)\n","\n","            for gauge_metric in resources_dict[resource_type][\"gauge_metrics\"]:\n","                if gauge_metric not in uuid_results_dict[uuid][group_filter_name]:\n","                    uuid_results_dict[uuid][group_filter_name][gauge_metric] = []\n","\n","                average_metric_value = process_gauge_metric_for_single_resource(\n","                    single_resource_data,\n","                    gauge_metric,\n","                    resources_dict[resource_type][\"group_by_columns\"],\n","                )\n","\n","                uuid_results_dict[uuid][group_filter_name][gauge_metric].append(\n","                    average_metric_value\n","                )\n","\n","    final_results_dict = {}\n","\n","    for uuid in uuid_results_dict:\n","\n","        for group_filter_name in uuid_results_dict[uuid]:\n","\n","            for metric_name in uuid_results_dict[uuid][group_filter_name]:\n","\n","                # sum of metric values across resources of specific category\n","                # (for example airflow-worker containers)\n","                sum_of_values = np.sum(\n","                    uuid_results_dict[uuid][group_filter_name][metric_name]\n","                )\n","\n","                uuid_results_dict[uuid][group_filter_name][metric_name] = sum_of_values\n","\n","                if np.isnan(sum_of_values):\n","                    warnings.warn(\n","                        f\"Nan value encountered when calculating value of {metric_name} \"\n","                        f\"for {group_filter_name} category of resources for uuid {uuid}. \"\n","                        f\"Skipping this uuid in calculating mean value of this metric \"\n","                        f\"for this resource category.\"\n","                    )\n","                    continue\n","\n","                category = \"__\".join([group_filter_name, metric_name])\n","\n","                if category not in final_results_dict:\n","                    final_results_dict[category] = []\n","\n","                final_results_dict[category].append(sum_of_values)\n","\n","    # finally, calculate mean of values across different test attempts (different uuids)\n","    for category in final_results_dict:\n","\n","        final_results_dict[category] = np.mean(final_results_dict[category])\n","\n","    # first row for every test attempt\n","    general_results = configuration_data.groupby([\"uuid\"]).first()\n","\n","    # calculate mean for non-time-series metrics\n","    for general_metric in general_metrics:\n","        general_metric_mean = general_results[general_metric].mean()\n","        if np.isnan(general_metric_mean):\n","            warnings.warn(\n","                f\"{general_metric} for all test attempts in one of configurations is nan.\"\n","            )\n","            continue\n","        final_results_dict[general_metric] = general_metric_mean\n","\n","    # TODO: add information about amount of uuids that contributed to each of averages\n","\n","    final_results_dict[\"test_attempts\"] = len(general_results)\n","\n","    return uuid_results_dict, final_results_dict\n","\n","\n","def check_if_group_filters_apply(\n","    group_name: Tuple[str, ...],\n","    group_filters: Dict[str, Dict],\n","    group_by_columns: List[str],\n",") -> Optional[str]:\n","    \"\"\"\n","    Returns first of group_filters specified for the resource type that applies to given group_name\n","    or None if none of them applies to this group.\n","\n","    :param group_name: tuple that identifies a single group created as a result of grouping\n","        configuration_data by group_by_columns.\n","    :type group_name: Tuple[str, ...]\n","    :param group_filters: a dictionary containing filters which control how groups of given resource\n","        type should be aggregated.\n","    :type group_filters: Dict[str, Dict]\n","    :param group_by_columns: list of columns by which configuration_data was grouped to calculate\n","        performance of given resource type.\n","    :type group_by_columns: List[str]\n","\n","    :return: name of the first filter that fully applies to group_name or None\n","        if none of them applies.\n","    :rtype: Optional[str]\n","\n","    :raises: ValueError: if one of group filters contains filter on column that is not\n","        amongst columns by which metrics of single test attempt were grouped.\n","    \"\"\"\n","\n","    for filter_name in group_filters:\n","\n","        for column_filter in group_filters[filter_name]:\n","\n","            if column_filter.endswith(PREFIX_LABEL_INDICATOR):\n","                column_name = column_filter[: -(len(PREFIX_LABEL_INDICATOR))]\n","                expected_column_value = group_filters[filter_name][column_filter]\n","                matching_function = column_value_starts_with\n","            else:\n","                column_name = column_filter\n","                expected_column_value = group_filters[filter_name][column_filter]\n","                matching_function = column_value_equals\n","\n","            if column_name not in group_by_columns:\n","                raise ValueError(\n","                    f\"Group filter {filter_name} contains filter on column {column_name} \"\n","                    f\"that is not amongst columns \"\n","                    f\"by which this resource is grouped: {group_by_columns}.\"\n","                )\n","\n","            index = group_by_columns.index(column_name)\n","\n","            column_value = group_name[index]\n","\n","            # if at least one column filter does not apply, then check next group of filters\n","            if not matching_function(column_value, expected_column_value):\n","                break\n","\n","        # if all column_filter from given group_filter apply then we have found\n","        # a match\n","        else:\n","            return filter_name\n","\n","    return None\n","\n","\n","def column_value_starts_with(column_value: str, expected_value: str) -> bool:\n","    \"\"\"\n","    Returns True if column_value starts with expected_value and False otherwise\n","    \"\"\"\n","    return column_value.startswith(expected_value)\n","\n","\n","def column_value_equals(column_value: str, expected_value: str) -> bool:\n","    \"\"\"\n","    Returns True if column_value is equal to expected_value and False otherwise\n","    \"\"\"\n","    return column_value == expected_value\n","\n","\n","def process_gauge_metric_for_single_resource(\n","    single_resource_data: pd.DataFrame, metric: str, group_by_columns: List[str]\n",") -> float:\n","    \"\"\"\n","    Calculates average value of gauge metric for single resource\n","    (node, pod or container) in given test attempt.\n","\n","    :param single_resource_data: pandas DataFrame which contains time series data of single resource\n","        (single node, pod or container).\n","    :type single_resource_data: pd.DataFrame\n","    :param metric: name of gauge metric average of which should be calculated.\n","    :type metric: str\n","    :param group_by_columns: list of columns by which configuration_data was grouped to calculate\n","        performance of given resource type.\n","    :type group_by_columns: List[str]\n","\n","    :return: float value with average of provided metric or np.nan if DataFrame did not contain a\n","        single value of that metric.\n","    :rtype: float\n","    \"\"\"\n","\n","    count = single_resource_data[metric].count()\n","\n","    # count is 0 if metric column consists only of nans\n","    if count == 0:\n","        warnings.warn(\n","            f\"It seems that {metric} contains only nan values for \"\n","            f\"{identify_resource(single_resource_data, group_by_columns)}. Returning nan.\"\n","        )\n","        return np.nan\n","\n","    return single_resource_data[metric].sum() / count\n","\n","\n","def process_cumulative_metric_for_single_resource(\n","    single_resource_data: pd.DataFrame, metric: str, group_by_columns: List[str]\n",") -> float:\n","    \"\"\"\n","    Calculates average growth of cumulative metric over time for single resource\n","    (node, pod or container) in given test attempt.\n","\n","    :param single_resource_data: pandas DataFrame which contains time series data of single resource\n","        (single node, pod or container). Must be sorted by timestamp.\n","    :type single_resource_data: pd.DataFrame\n","    :param metric: name of cumulative metric average growth of which should be calculated.\n","    :type metric: str\n","    :param group_by_columns: list of columns by which configuration_data was grouped to calculate\n","        performance of given resource type.\n","    :type group_by_columns: List[str]\n","\n","    :return: float value with average growth per second of provided metric or np.nan if DataFrame\n","        contains less than two values of that metric.\n","    :rtype: float\n","\n","    :raises: ValueError: if metric does not follow the constraints of cumulative metric\n","    \"\"\"\n","\n","    min_value = np.nan\n","\n","    for _, row in single_resource_data.iterrows():\n","        metric_value = row[metric]\n","\n","        if np.isnan(metric_value):\n","            continue\n","\n","        if np.isnan(min_value):\n","            min_value = metric_value\n","            current_max_value = metric_value\n","\n","            min_timestamp = row[\"timestamp\"]\n","            current_max_timestamp = row[\"timestamp\"]\n","            continue\n","\n","        # the same value as in previous non-nan timestamp is allowed\n","        if metric_value < current_max_value:\n","            # TODO: check what happens when pod/container gets restarted\n","            raise ValueError(\n","                f\"Error when calculating {metric} for \"\n","                f\"{identify_resource(single_resource_data, group_by_columns)}. \"\n","                f\"The value in latter timestamp is smaller than in a previous one.\"\n","            )\n","\n","        current_max_value = metric_value\n","        current_max_timestamp = row[\"timestamp\"]\n","\n","    if np.isnan(min_value):\n","        warnings.warn(\n","            f\"It seems that metric {metric} contains only nan values for \"\n","            f\"{identify_resource(single_resource_data, group_by_columns)}. Returning nan.\"\n","        )\n","        return np.nan\n","\n","    if min_timestamp == current_max_timestamp:\n","        warnings.warn(\n","            f\"It seems that metric {metric} contains only a single non-nan value for \"\n","            f\"{identify_resource(single_resource_data, group_by_columns)}. and its growth \"\n","            f\"cannot be calculated. Returning nan.\"\n","        )\n","        return np.nan\n","\n","    growth = (current_max_value - min_value) / (current_max_timestamp - min_timestamp)\n","\n","    return growth\n","\n","    # in case of 'breaks' in rising of cumulative metric\n","    # (for example due to pod restart) we could probably take\n","    # the total increase of metric value divided by total timespan\n","\n","    #\n","    # 7\n","    # 6       /\n","    # 5      /\n","    # 4     /\n","    # 3    /              /\n","    # 2   /              /\n","    # 1  /              /\n","    # 0  1  2  3  4  5  6  7  8\n","\n","    # so in this case:\n","    # increase: 6 + 3\n","    # timespan: 2 + 1\n","\n","\n","def identify_resource(\n","    single_resource_data: pd.DataFrame, group_by_columns: List[str]\n",") -> str:\n","    \"\"\"\n","    Returns a string identifying the resource data of which is stored in single_resource_data.\n","\n","    :param single_resource_data: pandas DataFrame which contains time series data of single resource\n","        (single node, pod or container).\n","    :type single_resource_data: pd.DataFrame\n","    :param group_by_columns: list of columns by which configuration_data was grouped to calculate\n","        performance of this resource type.\n","    :type group_by_columns: List[str]\n","\n","    :return: string identifying the resource.\n","    :rtype: str\n","    \"\"\"\n","    string_parts = []\n","\n","    for column in group_by_columns:\n","\n","        string_parts.append(f\"{column}: {single_resource_data[column].iloc[0]}\")\n","\n","    return \", \".join(string_parts)\n"],"execution_count":111,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jBKMGpauG1Bf","colab_type":"text"},"source":["Environment setup\n","\n","ENVIRONMENT_CONFIGURATION (1 and 2) are dicts specifying the configuration for which results summary should be done. Removing one of the keys will cause the test attempts with any value in the removed column to be included in the calculations.\n","\n","TIME_SERIES_METRICS is a set of column names with time series metrics which should be included in the summary of performance. If a column is not present for one of the test attempts (for example because corresponding metric was added recently) then given test attempt will simply not partake in calculating average of this metric.\n","\n","GENERAL_METRICS is a set of column names that contain metrics which refer to the whole test attempt. Similarly to TIME_SERIES_METRICS, if a column is not present for some uuids, then they will be excluded from calculation of average.\n","\n","RESOURCES_DICT is a dictionary that describes which time series metrics apply to which resource type, as well as by which columns data should be grouped in order to calculate average performance for given resource type correctly. Optionally, every resource type can also specify group_filters, which describe how the created groups should be aggregated. For example, you can specify that average of container metrics should be calculated separately only for 'airflow-worker' and 'airflow-scheduler' containers. Not specifying any group_filter causes all resorces of given type to be included in calculations."]},{"cell_type":"code","metadata":{"id":"U_7kd7T_G1QQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594646147205,"user_tz":-120,"elapsed":889,"user":{"displayName":"Kamil Olszewski","photoUrl":"","userId":"11407310702921568773"}}},"source":["PROJECT_ID = \"polidea-airflow\"\n","DATASET = \"characteristics_dataset\"\n","\n","ENVIRONMENT_CONFIGURATION_1 = {\n","    \"composer_version\": \"1.10.3\",\n","    \"airflow_version\": \"1.10.6\",\n","    \"python_version\": \"2.7.12\",\n","    \"environment_size\": \"small\",\n","    \"elastic_dag_configuration_type\": \"no_structure__200_dags__1_tasks__1_dag_runs__0.0_sleep__python_operator\",\n","    \"private_ip_enabled\": False,\n","    \"drs_enabled\": False,\n","    \"AIRFLOW__CORE__STORE_SERIALIZED_DAGS\": False,\n","}\n","\n","ENVIRONMENT_CONFIGURATION_2 = {\n","    \"composer_version\": \"1.10.4\",\n","    \"airflow_version\": \"1.10.6\",\n","    \"python_version\": \"2.7.12\",\n","    \"environment_size\": \"small\",\n","    \"elastic_dag_configuration_type\": \"no_structure__200_dags__1_tasks__1_dag_runs__0.0_sleep__python_operator\",\n","    \"private_ip_enabled\": False,\n","    \"drs_enabled\": False,\n","    \"AIRFLOW__CORE__STORE_SERIALIZED_DAGS\": False,\n","}\n","\n","# set of metrics that refer to time series data\n","TIME_SERIES_METRICS = {\n","    \"k8s_node__CUMULATIVE__kubernetes_io_node_cpu_core_usage_time\",\n","    \"k8s_node__CUMULATIVE__kubernetes_io_node_network_received_bytes_count\",\n","    \"k8s_node__CUMULATIVE__kubernetes_io_node_network_sent_bytes_count\",\n","    \"k8s_node__GAUGE__kubernetes_io_node_memory_used_bytes__memory_type_evictable\", \n","    \"k8s_node__GAUGE__kubernetes_io_node_memory_used_bytes__memory_type_non_evictable\",\n","    \"k8s_pod__CUMULATIVE__kubernetes_io_pod_network_received_bytes_count\",\n","    \"k8s_pod__CUMULATIVE__kubernetes_io_pod_network_sent_bytes_count\",\n","    \"k8s_container__CUMULATIVE__kubernetes_io_container_cpu_core_usage_time\",\n","    \"k8s_container__GAUGE__kubernetes_io_container_memory_used_bytes__memory_type_evictable\",\n","    \"k8s_container__GAUGE__kubernetes_io_container_memory_used_bytes__memory_type_non_evictable\",   \n","}\n","\n","# set of metrics that refer to the whole test attempt;\n","# their average across diferent test attempts will be calculated\n","GENERAL_METRICS = {\n","    \"test_duration\",\n","    \"dag_run_average_duration\",\n","    \"task_instance_average_duration\",\n","}\n","\n","# group filters should only include the columns from group_by_keys list\n","RESOURCES_DICT = {\n","    \"k8s_node\": {\n","        \"group_by_columns\": [\"uuid\", \"node_name\"]\n","    },\n","    \"k8s_pod\": {\n","        \"group_by_columns\": [\"uuid\", \"pod_name\"],\n","        \"group_filters\": {\n","            \"airflow-scheduler\": {\n","                \"pod_name_prefix\": \"airflow-scheduler\"\n","            },\n","            \"airflow-worker\": {\n","                \"pod_name_prefix\": \"airflow-worker\"\n","            },\n","        }\n","    },\n","    \"k8s_container\": {\n","        \"group_by_columns\": [\"uuid\", \"pod_name\", \"container_name\"],\n","        \"group_filters\": {\n","            \"airflow-scheduler\": {\n","                \"container_name\": \"airflow-scheduler\"\n","            },\n","            \"airflow-worker\": {\n","                \"container_name\": \"airflow-worker\"\n","            },\n","        }\n","    }\n","}\n","\n","assign_time_series_metrics(RESOURCES_DICT, TIME_SERIES_METRICS)"],"execution_count":112,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ykMax9KyE7Ld","colab_type":"text"},"source":["Collect data from BQ and save it in DF variable\n"]},{"cell_type":"code","metadata":{"id":"2Vo4211uIOeZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594628283188,"user_tz":-120,"elapsed":11937,"user":{"displayName":"Kamil Olszewski","photoUrl":"","userId":"11407310702921568773"}}},"source":["CLIENT = bigquery.Client(project=PROJECT_ID)\n","\n","QUERY = f'SELECT * FROM `{PROJECT_ID}.{DATASET}.*`'\n","PERFORMANCE_TEST_DATA = CLIENT.query(QUERY).to_dataframe()\n","\n","# replace nans in configuration columns added at later point with their default values\n","for column in CONFIGURATION_COLUMNS_DEFAULT_VALUES:\n","    if CONFIGURATION_COLUMNS_DEFAULT_VALUES[column] is not None:\n","        PERFORMANCE_TEST_DATA[column] = PERFORMANCE_TEST_DATA[column].fillna(\n","            CONFIGURATION_COLUMNS_DEFAULT_VALUES[column]\n","        )"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ByakXf-f-Gtb","colab_type":"text"},"source":["Compare results for two configurations"]},{"cell_type":"code","metadata":{"id":"6z7LskpKERex","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1594646250720,"user_tz":-120,"elapsed":1751,"user":{"displayName":"Kamil Olszewski","photoUrl":"","userId":"11407310702921568773"}},"outputId":"e66d7a30-240d-41f2-d31a-53a2804dfbb4"},"source":["comparison_df, test_attempts_per_missing_conf_1, test_attempts_per_missing_conf_2 = compare_performance_of_two_configurations(\n","    all_perf_test_data=PERFORMANCE_TEST_DATA,\n","    resources_dict=RESOURCES_DICT,\n","    general_metrics=GENERAL_METRICS,\n","    env_conf_1=ENVIRONMENT_CONFIGURATION_1,\n","    env_conf_2=ENVIRONMENT_CONFIGURATION_2,\n","    include_test_attempts_with_failed_dag_runs=False,\n",")\n","\n","print(tabulate(comparison_df, headers='keys', tablefmt='psql', floatfmt=f\".{PRECISION}f\"))\n","\n","if test_attempts_per_missing_conf_1 is not None:\n","    print()\n","    print(\"Detailed information about configurations belonging to first configuration dict.\")\n","    print(tabulate(test_attempts_per_missing_conf_1, headers='keys', tablefmt='psql'))\n","\n","if test_attempts_per_missing_conf_2 is not None:\n","    print()\n","    print(\"Detailed information about configurations belonging to second configuration dict.\")\n","    print(tabulate(test_attempts_per_missing_conf_2, headers='keys', tablefmt='psql'))"],"execution_count":115,"outputs":[{"output_type":"stream","text":["+----+---------------------------------------------------------------------------------------------------------------+-------------------+-------------------+--------------+\n","|    | category                                                                                                      |   configuration_1 |   configuration_2 | difference   |\n","|----+---------------------------------------------------------------------------------------------------------------+-------------------+-------------------+--------------|\n","|  0 | airflow-scheduler__k8s_container__CUMULATIVE__kubernetes_io_container_cpu_core_usage_time_per_second          |            0.2589 |            0.2524 | -2.5106%     |\n","|  1 | airflow-scheduler__k8s_container__GAUGE__kubernetes_io_container_memory_used_bytes__memory_type_evictable     |      1105011.8095 |      1183470.3915 | +7.1002%     |\n","|  2 | airflow-scheduler__k8s_container__GAUGE__kubernetes_io_container_memory_used_bytes__memory_type_non_evictable |    245307849.1429 |    254181590.0106 | +3.6174%     |\n","|  3 | airflow-scheduler__k8s_pod__CUMULATIVE__kubernetes_io_pod_network_received_bytes_count_per_second             |        92933.2922 |        94514.5190 | +1.7015%     |\n","|  4 | airflow-scheduler__k8s_pod__CUMULATIVE__kubernetes_io_pod_network_sent_bytes_count_per_second                 |        63768.1145 |        65036.6512 | +1.9893%     |\n","|  5 | airflow-worker__k8s_container__CUMULATIVE__kubernetes_io_container_cpu_core_usage_time_per_second             |            1.4164 |            1.3972 | -1.3555%     |\n","|  6 | airflow-worker__k8s_container__GAUGE__kubernetes_io_container_memory_used_bytes__memory_type_evictable        |      7611503.7460 |      9203243.3439 | +20.9123%    |\n","|  7 | airflow-worker__k8s_container__GAUGE__kubernetes_io_container_memory_used_bytes__memory_type_non_evictable    |   2786002133.3333 |   2447779573.1640 | -12.1401%    |\n","|  8 | airflow-worker__k8s_pod__CUMULATIVE__kubernetes_io_pod_network_received_bytes_count_per_second                |       134593.5539 |       132220.2567 | -1.7633%     |\n","|  9 | airflow-worker__k8s_pod__CUMULATIVE__kubernetes_io_pod_network_sent_bytes_count_per_second                    |        64570.0601 |        62967.5211 | -2.4819%     |\n","| 10 | all__k8s_node__CUMULATIVE__kubernetes_io_node_cpu_core_usage_time_per_second                                  |            2.7045 |            2.6580 | -1.7194%     |\n","| 11 | all__k8s_node__CUMULATIVE__kubernetes_io_node_network_received_bytes_count_per_second                         |       476226.6486 |       452382.1460 | -5.007%      |\n","| 12 | all__k8s_node__CUMULATIVE__kubernetes_io_node_network_sent_bytes_count_per_second                             |       400549.3728 |       370049.4924 | -7.6145%     |\n","| 13 | all__k8s_node__GAUGE__kubernetes_io_node_memory_used_bytes__memory_type_evictable                             |   2215997750.8571 |   2296047580.7831 | +3.6124%     |\n","| 14 | all__k8s_node__GAUGE__kubernetes_io_node_memory_used_bytes__memory_type_non_evictable                         |   6045232540.4444 |   5834428439.0265 | -3.4871%     |\n","| 15 | dag_run_average_duration                                                                                      |          559.6109 |          590.7157 | +5.5583%     |\n","| 16 | task_instance_average_duration                                                                                |           33.4370 |           34.0794 | +1.9212%     |\n","| 17 | test_attempts                                                                                                 |            4.0000 |            6.0000 | +50.0%       |\n","| 18 | test_duration                                                                                                 |         1018.4216 |         1091.6199 | +7.1874%     |\n","+----+---------------------------------------------------------------------------------------------------------------+-------------------+-------------------+--------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8xXTevZmJpIi","colab_type":"text"},"source":["Analyze results for single configuration"]},{"cell_type":"code","metadata":{"id":"gKpXizTrv4L8","colab_type":"code","colab":{}},"source":["configuration_data = collect_results_for_configuration(PERFORMANCE_TEST_DATA, ENVIRONMENT_CONFIGURATION_1)\n","\n","uuid_results_1, configuration_1_total_results = calculate_statistics_for_configuration(configuration_data, RESOURCES_DICT, GENERAL_METRICS)\n","\n","print(json.dumps(configuration_1_total_results, indent=4, sort_keys=True))\n","print()\n","print(json.dumps(uuid_results_1, indent=4, sort_keys=True))"],"execution_count":null,"outputs":[]}]}
