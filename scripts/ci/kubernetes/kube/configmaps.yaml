#  Licensed to the Apache Software Foundation (ASF) under one   *
#  or more contributor license agreements.  See the NOTICE file *
#  distributed with this work for additional information        *
#  regarding copyright ownership.  The ASF licenses this file   *
#  to you under the Apache License, Version 2.0 (the            *
#  "License"); you may not use this file except in compliance   *
#  with the License.  You may obtain a copy of the License at   *
#                                                               *
#    http://www.apache.org/licenses/LICENSE-2.0                 *
#                                                               *
#  Unless required by applicable law or agreed to in writing,   *
#  software distributed under the License is distributed on an  *
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY       *
#  KIND, either express or implied.  See the License for the    *
#  specific language governing permissions and limitations      *
#  under the License.                                           *
apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-configmap
data:
  airflow.cfg: |
    [core]
    airflow_home = /root/airflow
    dags_folder = /root/airflow/dags
    base_log_folder = /root/airflow/logs
    logging_level = INFO
    executor = KubernetesExecutor
    parallelism = 32
    load_examples = True
    plugins_folder = /root/airflow/plugins
    sql_alchemy_conn = $SQL_ALCHEMY_CONN

    [scheduler]
    dag_dir_list_interval = 300
    child_process_log_directory = /root/airflow/logs/scheduler
    # Task instances listen for external kill signal (when you clear tasks
    # from the CLI or the UI), this defines the frequency at which they should
    # listen (in seconds).
    job_heartbeat_sec = 5
    max_threads = 16

    # The scheduler constantly tries to trigger new tasks (look at the
    # scheduler section in the docs for more information). This defines
    # how often the scheduler should run (in seconds).
    scheduler_heartbeat_sec = 5

    # after how much time should the scheduler terminate in seconds
    # -1 indicates to run continuously (see also num_runs)
    run_duration = -1

    # after how much time a new DAGs should be picked up from the filesystem
    min_file_process_interval = 0

    statsd_on = False
    statsd_host = localhost
    statsd_port = 8125
    statsd_prefix = airflow

    # How many seconds to wait between file-parsing loops to prevent the logs from being spammed.
    min_file_parsing_loop_time = 1

    print_stats_interval = 30
    scheduler_zombie_task_threshold = 300
    max_tis_per_query = 0
    authenticate = False

    [kubernetes]
    airflow_configmap = airflow-configmap
    worker_container_repository = airflow
    worker_container_tag = latest
    delete_worker_pods = True
    git_repo = https://github.com/grantnicholas/testdags.git
    git_branch = master
    dags_volume_claim = airflow-dags
    logs_volume_claim = airflow-logs
    in_cluster = True

    [kubernetes_secrets]
    SQL_ALCHEMY_CONN = airflow-secrets=sql_alchemy_conn
