# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
---
name: Publish Docs to S3
on:  # yamllint disable-line rule:truthy
  workflow_dispatch:
    inputs:
      ref:
        description: "The branch or tag to checkout for the docs publishing"
        required: true
        type: string
      include-docs:
        description: |
          Space separated list of docs to build.
          To publish docs for nested provider packages, provide the package name with `.`
          eg: amazon common.messaging apache.kafka

        required: false
        default: "all-providers"
        type: string
      exclude-docs:
        description: "Comma separated list of docs to exclude"
        required: false
        default: "no-docs-excluded"
        type: string
      destination-location:
        description: "The destination location in S3, default is live site"
        required: false
        default: "s3://live-docs-airflow-apache-org/docs"
        type: choice
        options:
          - s3://live-docs-airflow-apache-org/docs
          - s3://staging-docs-airflow-apache-org/docs

env:
  AIRFLOW_ROOT_PATH: "/home/runner/work/temp-airflow-repo-reference"  # checkout dir for referenced tag
permissions:
  contents: read
jobs:
  build-info:
    timeout-minutes: 10
    name: "Build Info"
    runs-on: ["ubuntu-24.04"]
    env:
      GITHUB_CONTEXT: ${{ toJson(github) }}
      VERBOSE: true
      REF: ${{ inputs.ref }}
      INCLUDE_DOCS: ${{ inputs.include-docs }}
      EXCLUDE_DOCS: ${{ inputs.exclude-docs }}
      DESTINATION_LOCATION: ${{ inputs.destination-location }}
    outputs:
      include-docs: ${{ inputs.include-docs == 'all' && '' || inputs.include-docs }}
    if: contains(fromJSON('[
      "ashb",
      "eladkal",
      "ephraimbuddy",
      "jedcunningham",
      "kaxil",
      "pierrejeambrun",
      "potiuk",
      "utkarsharma2"
      ]'), github.event.sender.login)
    steps:
      - name: "Input parameters summary"
        shell: bash
        run: |
          echo "Input parameters summary"
          echo "========================="
          echo "Ref: '${REF}'"
          echo "Included docs : '${INCLUDE_DOCS}'"
          echo "Exclude docs: '${EXCLUDE_DOCS}'"
          echo "Destination location: '${DESTINATION_LOCATION}'"

  build-ci-images:
    name: Build CI images
    uses: ./.github/workflows/ci-image-build.yml
    needs: [build-info]
    permissions:
      contents: read
      # This write is only given here for `push` events from "apache/airflow" repo. It is not given for PRs
      # from forks. This is to prevent malicious PRs from creating images in the "apache/airflow" repo.
      packages: write
    with:
      runners: '["ubuntu-22.04"]'
      platform: "linux/amd64"
      push-image: "false"
      upload-image-artifact: "true"
      upload-mount-cache-artifact: false
      python-versions: "['3.9']"
      branch: ${{ inputs.ref }}
      use-uv: true
      upgrade-to-newer-dependencies: false
      constraints-branch: "constraints-main"
      docker-cache: registry
      disable-airflow-repo-cache: false

  build-docs:
    needs: [build-ci-images, build-info]
    timeout-minutes: 150
    name: "Build documentation"
    runs-on: ubuntu-latest
    env:
      GITHUB_REPOSITORY: ${{ github.repository }}
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      GITHUB_USERNAME: ${{ github.actor }}
      INCLUDE_NOT_READY_PROVIDERS: "true"
      INCLUDE_SUCCESS_OUTPUTS: false
      PYTHON_MAJOR_MINOR_VERSION: 3.9
      VERBOSE: "true"
    steps:
      - name: "Cleanup repo"
        shell: bash
        run: docker run -v "${GITHUB_WORKSPACE}:/workspace" -u 0:0 bash -c "rm -rf /workspace/*"
      - name: "Checkout ${{ github.ref }} "
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: "Checkout from ${{ inputs.ref }} to build docs"
        run: |
          git clone https://github.com/apache/airflow.git "${AIRFLOW_ROOT_PATH}"
          cd "${AIRFLOW_ROOT_PATH}" && git checkout ${REF}
        env:
          REF: ${{ inputs.ref }}
      - name: "Prepare breeze & CI image: 3.9"
        uses: ./.github/actions/prepare_breeze_and_image
        with:
          platform: "linux/amd64"
          python: 3.9
          use-uv: true
      - name: "Building docs with --docs-only flag"
        env:
          INCLUDE_DOCS: ${{ needs.build-info.outputs.include-docs }}
        run: >
          breeze build-docs ${INCLUDE_DOCS} --docs-only --include-commits
      - name: "Upload build docs"
        uses: actions/upload-artifact@v4
        with:
          name: airflow-docs
          path: ${{ env.AIRFLOW_ROOT_PATH }}/generated/_build
          retention-days: '7'
          if-no-files-found: 'error'
          overwrite: 'true'

  publish-docs-to-s3:
    needs: [build-docs, build-info]
    name: "Publish documentation to S3"
    permissions:
      id-token: write
      contents: read
    runs-on: ubuntu-latest
    env:
      GITHUB_REPOSITORY: ${{ github.repository }}
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      GITHUB_USERNAME: ${{ github.actor }}
      INCLUDE_NOT_READY_PROVIDERS: "true"
      INCLUDE_SUCCESS_OUTPUTS: false
      PYTHON_MAJOR_MINOR_VERSION: 3.9
      VERBOSE: "true"
    steps:
      - name: "Cleanup repo"
        shell: bash
        run: docker run -v "${GITHUB_WORKSPACE}:/workspace" -u 0:0 bash -c "rm -rf /workspace/*"
      - name: "Checkout ${{ github.ref }} "
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: "Prepare and cleanup runner"
        run: ./scripts/ci/prepare_and_cleanup_runner.sh
      - name: "Checkout ${{ inputs.ref }}"
        run: |
          git clone https://github.com/apache/airflow.git "${AIRFLOW_ROOT_PATH}"
          cd "${AIRFLOW_ROOT_PATH}" && git checkout ${REF}
        env:
          REF: ${{ inputs.ref }}
      - name: "Download docs prepared as artifacts"
        uses: actions/download-artifact@v4
        with:
          name: airflow-docs
          path: ${{ env.AIRFLOW_ROOT_PATH }}/generated/_build
      - name: Check disk space available
        run: df -H
      # Here we will create temp airflow-site dir to publish
      # docs and for back-references
      - name: Create /mnt/airflow-site directory
        run: |
          sudo mkdir -p /mnt/airflow-site && sudo chown -R "${USER}" /mnt/airflow-site
           echo "AIRFLOW_SITE_DIRECTORY=/mnt/airflow-site/" >> "$GITHUB_ENV"
      - name: "Prepare breeze & CI image: 3.9"
        uses: ./.github/actions/prepare_breeze_and_image
        with:
          platform: "linux/amd64"
          python: 3.9
          use-uv: true
      - name: "Publish docs to tmp directory"
        env:
          INCLUDE_DOCS: ${{ needs.build-info.outputs.include-docs }}
        run: >
          breeze release-management publish-docs --override-versioned --run-in-parallel
          ${INCLUDE_DOCS}
      - name: Check disk space available
        run: df -H
      - name: "Generate back references for providers"
        run: breeze release-management add-back-references all-providers
      - name: "Generate back references for apache-airflow"
        run: breeze release-management add-back-references apache-airflow
      - name: "Generate back references for docker-stack"
        run: breeze release-management add-back-references docker-stack
      - name: "Generate back references for helm-chart"
        run: breeze release-management add-back-references helm-chart
      - name: Install AWS CLI v2
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o /tmp/awscliv2.zip
          unzip -q /tmp/awscliv2.zip -d /tmp
          rm /tmp/awscliv2.zip
          sudo /tmp/aws/install --update
          rm -rf /tmp/aws/
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@010d0da01d0b5a38af31e9c3470dbfdabdecca3a  # v4.0.1
        with:
          aws-access-key-id: ${{ secrets.DOCS_AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.DOCS_AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-2
      - name: "Syncing docs to S3"
        env:
          DESTINATION_LOCATION: "${{ inputs.destination-location }}"
          SOURCE_DIR_PATH: "/mnt/airflow-site/docs-archive/"
          EXCLUDE_DOCS: "${{ inputs.exclude-docs }}"
        run: |
          breeze release-management publish-docs-to-s3 --source-dir-path ${SOURCE_DIR_PATH} \
          --destination-location ${DESTINATION_LOCATION} --stable-versions \
          --exclude-docs ${EXCLUDE_DOCS} --overwrite
