# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# NOTE! THIS FILE IS AUTOMATICALLY GENERATED AND WILL BE OVERWRITTEN!

# IF YOU WANT TO MODIFY THIS FILE EXCEPT DEPENDENCIES, YOU SHOULD MODIFY THE TEMPLATE
# `pyproject_TEMPLATE.toml.jinja2` IN the `dev/breeze/src/airflow_breeze/templates` DIRECTORY
[build-system]
requires = ["flit_core==3.12.0"]
build-backend = "flit_core.buildapi"

[project]
name = "apache-airflow-providers-databricks"
version = "7.8.2"
description = "Provider package apache-airflow-providers-databricks for Apache Airflow"
readme = "README.rst"
license = "Apache-2.0"
license-files = ['LICENSE', 'NOTICE']
authors = [
    {name="Apache Software Foundation", email="dev@airflow.apache.org"},
]
maintainers = [
    {name="Apache Software Foundation", email="dev@airflow.apache.org"},
]
keywords = [ "airflow-provider", "databricks", "airflow", "integration" ]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Environment :: Console",
    "Environment :: Web Environment",
    "Intended Audience :: Developers",
    "Intended Audience :: System Administrators",
    "Framework :: Apache Airflow",
    "Framework :: Apache Airflow :: Provider",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: System :: Monitoring",
]
requires-python = ">=3.10"

# The dependencies should be modified in place in the generated file.
# Any change in the dependencies is preserved when the file is regenerated
# Make sure to run ``prek update-providers-dependencies --all-files``
# After you modify the dependencies, and rebuild your Breeze CI image with ``breeze ci-image build``
dependencies = [
    "apache-airflow>=2.11.0",
    "apache-airflow-providers-common-compat>=1.10.1",  # use next version
    "apache-airflow-providers-common-sql>=1.27.0",
    "requests>=2.32.0,<3",
    "databricks-sql-connector>=4.0.0",
    "databricks-sqlalchemy>=1.0.2",
    "aiohttp>=3.9.2, <4",
    "mergedeep>=1.3.4",
    'pandas>=2.1.2; python_version <"3.13"',
    'pandas>=2.2.3; python_version >="3.13"',
    "pyarrow>=16.1.0; python_version < '3.13'",
    "pyarrow>=18.0.0; python_version >= '3.13'",
]

# The optional dependencies should be modified in place in the generated file
# Any change in the dependencies is preserved when the file is regenerated
[project.optional-dependencies]
# pip install apache-airflow-providers-databricks[sdk]
"sdk" = [
    "databricks-sdk==0.10.0",
]
"azure-identity" = [
    "azure-identity>=1.3.1",
]
"fab" = [
    "apache-airflow-providers-fab>=2.2.0; python_version < '3.13'"
]
"standard" = [
    "apache-airflow-providers-standard"
]
"openlineage" = [
    "apache-airflow-providers-openlineage>=2.3.0"
]

[dependency-groups]
dev = [
    "apache-airflow",
    "apache-airflow-task-sdk",
    "apache-airflow-devel-common",
    "apache-airflow-providers-common-compat",
    "apache-airflow-providers-common-sql",
    "apache-airflow-providers-openlineage",
    # Additional devel dependencies (do not remove this line and add extra development dependencies)
    "deltalake>=1.1.3",
    "apache-airflow-providers-fab>=2.2.0; python_version < '3.13'",
    "apache-airflow-providers-microsoft-azure",
    "apache-airflow-providers-common-sql[pandas,polars]",
    "apache-airflow-providers-fab",
]

# To build docs:
#
#    uv run --group docs build-docs
#
# To enable auto-refreshing build with server:
#
#    uv run --group docs build-docs --autobuild
#
# To see more options:
#
#    uv run --group docs build-docs --help
#
docs = [
    "apache-airflow-devel-common[docs]"
]

[tool.uv.sources]
# These names must match the names as defined in the pyproject.toml of the workspace items,
# *not* the workspace folder paths
apache-airflow = {workspace = true}
apache-airflow-devel-common = {workspace = true}
apache-airflow-task-sdk = {workspace = true}
apache-airflow-providers-common-sql = {workspace = true}
apache-airflow-providers-standard = {workspace = true}

[project.urls]
"Documentation" = "https://airflow.apache.org/docs/apache-airflow-providers-databricks/7.8.2"
"Changelog" = "https://airflow.apache.org/docs/apache-airflow-providers-databricks/7.8.2/changelog.html"
"Bug Tracker" = "https://github.com/apache/airflow/issues"
"Source Code" = "https://github.com/apache/airflow"
"Slack Chat" = "https://s.apache.org/airflow-slack"
"Mastodon" = "https://fosstodon.org/@airflow"
"YouTube" = "https://www.youtube.com/channel/UCSXwxpWZQ7XZ1WL3wqevChA/"

[project.entry-points."apache_airflow_provider"]
provider_info = "airflow.providers.databricks.get_provider_info:get_provider_info"

[project.entry-points."airflow.plugins"]
databricks_workflow = "airflow.providers.databricks.plugins.databricks_workflow:DatabricksWorkflowPlugin"

[tool.flit.module]
name = "airflow.providers.databricks"
