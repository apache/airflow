#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.


from __future__ import annotations

error_guide_dict: dict = {
    "AERR001": {
        "exception_type": "AirflowException",
        "error_message": "Dynamic task mapping exceeded limit",
        "description": "Happens when dynamically mapped tasks exceed the maximum number of tasks allowed.",
        "first_steps": "Check the task count limit in the configuration. Consider increasing the task limit or optimizing task mapping logic.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dynamic-task-mapping.html",
    },
    "AERR002": {
        "exception_type": "AirflowException",
        "error_message": "Task instance not found",
        "description": "Happens when the scheduler or webserver cannot locate a task instance in the database.",
        "first_steps": "Verify that the database connection is stable. Check if the task instances exist in the metadata database and consider re-running the DAG.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/task-instances.html",
    },
    "AERR003": {
        "exception_type": "AirflowException",
        "error_message": "Task is in 'None' state",
        "description": "Indicates a task instance has not been assigned a proper state, often due to missing execution context.",
        "first_steps": "Ensure that the task is correctly configured and the execution context is provided, especially for dynamic tasks or task dependencies.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dag-run.html#execution-context",
    },
    "AERR004": {
        "exception_type": "AirflowWebServerException",
        "error_message": "Webserver 502 Bad Gateway",
        "description": "Triggered when the webserver encounters an upstream issue or fails to proxy requests.",
        "first_steps": "Check the webserver logs for more details. Ensure all upstream systems are working properly, and restart the webserver if necessary.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/webserver.html#troubleshooting",
    },
    "AERR005": {
        "exception_type": "KeyError",
        "error_message": "KeyError in Variable retrieval",
        "description": "Occurs when a requested Airflow Variable is not found in the metadata database.",
        "first_steps": "Check if the Airflow variable exists. Ensure the correct database is used, and verify if the Airflow variable is defined in the Airflow UI or through code.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/variables.html",
    },
    "AERR006": {
        "exception_type": "PermissionError",
        "error_message": "Access denied for SSH hook",
        "description": "Triggered when the SSH hook cannot authenticate or connect to the target server.",
        "first_steps": "Verify the SSH credentials and network access to the target server. Test the connection using a manual SSH client before troubleshooting in Airflow.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/ssh.html",
    },
    "AERR007": {
        "exception_type": "AirflowXComException",
        "error_message": "TaskInstance not recognized in XCom",
        "description": "Happens when a task's XCom entry is missing or corrupted in the metadata database.",
        "first_steps": "Check if the XCom data is being pushed correctly. Inspect the DAG code for issues in data push logic, and consider clearing any corrupted XCom entries.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/xcoms.html",
    },
    "AERR008": {
        "exception_type": "AirflowDatabaseException",
        "error_message": "Duplicate XCom entry detected",
        "description": "Occurs when the same XCom key-value pair is inserted multiple times into the database.",
        "first_steps": "Ensure that the XCom key-value pair is unique for each task. Modify the DAG logic to avoid reusing keys or overwriting XCom entries.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/xcoms.html#avoiding-duplicate-keys",
    },
    "AERR009": {
        "exception_type": "AirflowDatabaseException",
        "error_message": "Error creating database session",
        "description": "Triggered when Airflow cannot create a new database session.",
        "first_steps": "Check the database connection settings and ensure the database is running. Verify user permissions and the number of concurrent connections allowed.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/set-up-database.html",
    },
    "AERR010": {
        "exception_type": "AirflowConfigException",
        "error_message": "Strict validation in Dataset URI breaks existing DAGs",
        "description": "Happens when a dataset URI is not compliant with stricter validation rules introduced in newer versions.",
        "first_steps": "Review the dataset URI format for compliance with new validation rules. Update the URI if necessary to meet the required standards.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/datasets.html#uri-validation",
    },
    "AERR011": {
        "exception_type": "AirflowException",
        "error_message": "Failed to upload logs to remote storage",
        "description": "Occurs when Airflow cannot push task logs to a configured remote storage backend.",
        "first_steps": "Check the configuration for the remote storage backend. Ensure that the connection credentials are correct and the backend is accessible.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/logging.html#remote-logging",
    },
    "AERR012": {
        "exception_type": "AirflowDatabaseException",
        "error_message": "Cannot connect to airflow database",
        "description": "Happens when the metadata database is unreachable due to network or configuration issues.",
        "first_steps": "Verify the network connection to the metadata database and check for any misconfigurations. Restart Airflow components if necessary.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/metadata-database.html",
    },
    "AERR013": {
        "exception_type": "KeyError",
        "error_message": "KeyError in retrieving XCom value",
        "description": "Occurs when a requested XCom value is not found or incorrectly defined.",
        "first_steps": "Ensure the XCom key and value are properly defined and passed between tasks. Double-check task execution order and parameter passing.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/xcoms.html#pushing-and-pulling-xcoms",
    },
    "AERR014": {
        "exception_type": "ImportError",
        "error_message": "Missing dependency for KubernetesExecutor",
        "description": "Occurs when the required dependencies for the KubernetesExecutor are not installed.",
        "first_steps": "Verify that all required dependencies for the KubernetesExecutor are installed. Use `pip` or your environment management tool to install missing packages.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/executors/kubernetes.html#kubernetes-executor",
    },
    "AERR015": {
        "exception_type": "AirflowDagPausedException",
        "error_message": "DAG is paused and not running",
        "description": "Indicates the DAG is manually paused and will not trigger scheduled runs.",
        "first_steps": "Check the DAG status in the Airflow UI and unpause the DAG if needed. Verify the DAG configuration and dependencies.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/dag-run.html#paused-dags",
    },
    "AERR016": {
        "exception_type": "AirflowTaskTimeout",
        "error_message": "Task execution delayed indefinitely",
        "description": "Happens when a task does not start execution within the specified timeout.",
        "first_steps": "Review the task timeout settings in the DAG configuration. Increase the timeout if necessary and check for system performance issues.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/operator.html#timeouts",
    },
    "AERR017": {
        "exception_type": "AirflowConfigException",
        "error_message": "Can't find executor class",
        "description": "Happens when the executor specified in the configuration file is not recognized or available.",
        "first_steps": "Verify the executor configuration in the `airflow.cfg` file. Ensure the specified executor is installed and supported by your Airflow version.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/executors/index.html",
    },
    "AERR018": {
        "exception_type": "AirflowConfigException",
        "error_message": "Invalid value in airflow.cfg file",
        "description": "Triggered when airflow.cfg contains an invalid or unsupported value.",
        "first_steps": "Review the `airflow.cfg` configuration file for errors or unsupported values. Consult the Airflow documentation for valid settings.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/configurations-ref.html",
    },
    "AERR019": {
        "exception_type": "AirflowCliException",
        "error_message": "Airflow CLI authentication failed",
        "description": "Occurs when CLI commands cannot authenticate with the Airflow backend.",
        "first_steps": "Check if the Airflow CLI has the proper credentials to access the backend. Ensure the correct connection configurations and environment variables are set.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/cli-and-commands.html#authentication",
    },
    "AERR020": {
        "exception_type": "AirflowTriggerException",
        "error_message": "Error triggering external API",
        "description": "Happens when a trigger for an external API fails to execute.",
        "first_steps": "Check the API endpoint and ensure it is reachable. Review the Airflow logs to see if there is an error in the API trigger logic.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/external-task.html",
    },
    "AERR021": {
        "exception_type": "AirflowDatabaseException",
        "error_message": "Database deadlock detected",
        "description": "Occurs when multiple processes are locked in conflicting database operations.",
        "first_steps": "Investigate the database for any deadlocks or conflicting operations. Optimize queries or increase database capacity to avoid locking issues.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/database-optimizations.html",
    },
    "AERR022": {
        "exception_type": "PermissionError",
        "error_message": "Permission error in KubernetesPodOperator",
        "description": "Occurs when the KubernetesPodOperator lacks permissions to perform required actions.",
        "first_steps": "Review the KubernetesPodOperator configuration and ensure it has the necessary permissions to perform actions in your Kubernetes cluster.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/kubernetes.html#permissions",
    },
    "AERR023": {
        "exception_type": "AirflowSchedulerException",
        "error_message": "Scheduler loop error",
        "description": "Triggered when the scheduler encounters an unexpected condition during its loop.",
        "first_steps": "Check the scheduler logs for specific error messages. Review recent changes to the Airflow environment or DAGs that could affect scheduler behavior.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/scheduler.html#troubleshooting-scheduler",
    },
    "AERR024": {
        "exception_type": "AirflowParseException",
        "error_message": "Broken DAG: syntax error",
        "description": "Occurs when a syntax error in the DAG file prevents it from being parsed.",
        "first_steps": "Review the DAG file for any syntax errors and correct them. Use a linter or Python syntax checker to help identify issues.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html#dags",
    },
    "AERR025": {
        "exception_type": "AirflowDatabaseException",
        "error_message": "DagRun state update failed",
        "description": "Occurs when Airflow fails to update the state of a DAG run in the database.",
        "first_steps": "Check the database connection and permissions. Review any database constraints or performance issues that could prevent state updates.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/metadata-database.html",
    },
    "AERR026": {
        "exception_type": "AirflowTaskTimeout",
        "error_message": "Task marked as failed due to timeout",
        "description": "Happens when a task exceeds its maximum allowable execution time.",
        "first_steps": "Increase the task execution timeout in the DAG configuration. Investigate the task logic for inefficiencies or external system delays.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/operator.html#timeouts",
    },
    "AERR027": {
        "exception_type": "FileNotFoundError",
        "error_message": "Task log not found",
        "description": "Happens when task logs are missing from the local or remote storage.",
        "first_steps": "Check the task log configuration in Airflow. Ensure that logging paths are correctly configured and accessible. Verify permissions for remote storage.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/logging.html#task-logging",
    },
    "AERR028": {
        "exception_type": "ImportError",
        "error_message": "Cannot import module in BashOperator",
        "description": "Triggered when a script run by BashOperator references missing Python modules.",
        "first_steps": "Ensure all required Python modules are installed in the environment. Check the `requirements.txt` or virtual environment for missing dependencies.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/bash.html#bashoperator",
    },
    "AERR029": {
        "exception_type": "AirflowConfigException",
        "error_message": "Error loading connections from secret",
        "description": "Happens when Airflow fails to load connection credentials from a secret backend.",
        "first_steps": "Check the secret backend configuration and credentials. Ensure the secret backend is accessible and correctly set up in Airflow.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/security/secrets.html",
    },
    "AERR030": {
        "exception_type": "AirflowWorkerException",
        "error_message": "Worker not responding",
        "description": "Happens when a worker node becomes unresponsive or fails to report its status.",
        "first_steps": "Check the worker node logs for errors. Restart the worker node if necessary and verify network connectivity between the scheduler and worker.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/worker.html",
    },
    "AERR031": {
        "exception_type": "AirflowException",
        "error_message": "Resource not found in GCP hook",
        "description": "Triggered when a GCP hook is unable to locate the specified resource.",
        "first_steps": "Verify the resource exists in GCP. Check the GCP credentials and ensure that the hook is correctly configured to access the resource.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow-providers-google/stable/index.html",
    },
    "AERR032": {
        "exception_type": "AirflowExecutorException",
        "error_message": "Backend not reachable for Celery",
        "description": "Occurs when the CeleryExecutor cannot connect to the configured Celery backend.",
        "first_steps": "Check the Celery backend configuration in `airflow.cfg`. Verify network access and that the Celery worker is properly connected and running.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/executors/celery.html",
    },
    "AERR033": {
        "exception_type": "AirflowException",
        "error_message": "Invalid cron expression",
        "description": "Occurs when the cron schedule provided in the DAG is invalid or unparsable.",
        "first_steps": "Check the cron expression syntax for errors. Use a cron expression validator tool to confirm it is valid and properly formatted.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/scheduler.html#scheduling-dags",
    },
    "AERR034": {
        "exception_type": "UnpicklingError",
        "error_message": "UnpicklingError while running task",
        "description": "Happens when Airflow cannot deserialize data, often due to incompatible Python versions or corrupted data.",
        "first_steps": "Ensure that Airflow and its dependencies are compatible with the Python version in use. Review any corrupted data and clear invalid entries.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/serialization.html",
    },
    "AERR035": {
        "exception_type": "AirflowWorkerException",
        "error_message": "Task instance killed by external system",
        "description": "Occurs when an external system terminates a task instance during execution.",
        "first_steps": "Review the external system logs to determine why it terminated the task. Modify task handling to account for external termination events.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/operators.html#external-task-sensor",
    },
    "AERR036": {
        "exception_type": "AirflowWorkerException",
        "error_message": "Worker died during task execution",
        "description": "Happens when the worker process handling a task crashes or is terminated.",
        "first_steps": "Investigate the worker logs to identify the cause of the crash. Ensure that the worker environment has adequate resources and is properly configured.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/worker.html#troubleshooting",
    },
    "AERR037": {
        "exception_type": "AirflowDatabaseException",
        "error_message": "Failed to fetch task state",
        "description": "Occurs when the metadata database does not return a valid state for a task instance.",
        "first_steps": "Check the metadata database for data consistency and ensure that the database is responsive. Investigate for any database corruption or misconfigurations.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/metadata-database.html",
    },
    "AERR038": {
        "exception_type": "ValueError",
        "error_message": "Cron interval parsing failed",
        "description": "Occurs when the cron expression for a DAG's schedule interval cannot be parsed.",
        "first_steps": "Review the cron expression in the DAG configuration. Use a cron expression validator to confirm the format is correct and supported by Airflow.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/scheduler.html#scheduling-dags",
    },
    "AERR039": {
        "exception_type": "AirflowSchedulerException",
        "error_message": "Scheduler throttled due to excessive DAGs",
        "description": "Happens when the scheduler takes too long to process a large number of DAGs.",
        "first_steps": "Consider optimizing DAG execution and task scheduling. Check the scheduler logs for any performance bottlenecks, and adjust the scheduler settings to handle large DAGs efficiently.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/scheduler.html#scheduler-performance",
    },
    "AERR040": {
        "exception_type": "AirflowDatabaseException",
        "error_message": "DagRun execution_date conflicts",
        "description": "Occurs when there is a mismatch in execution_date for a DAG run in the database.",
        "first_steps": "Ensure the execution_date is correctly defined and consistent across task instances. Check for any issues with time zone settings or manual overrides.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dag-run.html",
    },
    "AERR041": {
        "exception_type": "AirflowTaskTimeout",
        "error_message": "Task is stuck in queued state",
        "description": "Occurs when a task remains queued without being picked up by an executor.",
        "first_steps": "Check the executor configuration and ensure that sufficient worker nodes are available. Verify the queue settings and make sure the task is being routed to the correct executor.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/task-instance.html#queued",
    },
    "AERR042": {
        "exception_type": "AirflowParseException",
        "error_message": "Error while parsing DAG file",
        "description": "Triggered when the scheduler encounters syntax errors or invalid code in a DAG file.",
        "first_steps": "Review the DAG file for any code errors or invalid syntax. Use a Python linter to catch issues before loading the DAG into Airflow.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html#dags",
    },
    "AERR043": {
        "exception_type": "AirflowDagCycleException",
        "error_message": "Task dependency cycle detected",
        "description": "Triggered when task dependencies in a DAG create an infinite loop.",
        "first_steps": "Check task dependencies in the DAG and ensure that there are no circular references. Modify dependencies to prevent infinite loops.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html#task-dependencies",
    },
    "AERR044": {
        "exception_type": "AirflowTaskException",
        "error_message": "Task failed due to retries exceeded",
        "description": "Triggered when a task exhausts its retry limit without succeeding.",
        "first_steps": "Increase the retry limit in the DAG configuration or modify the task logic to handle failure scenarios more gracefully.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/operator.html#retries",
    },
    "AERR045": {
        "exception_type": "ValueError",
        "error_message": "ValueError in task arguments",
        "description": "Happens when a task operator is provided with invalid or incompatible arguments.",
        "first_steps": "Review the operator arguments and ensure they are correctly specified. Check the Airflow documentation for valid arguments for the operator used.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator.html",
    },
    "AERR046": {
        "exception_type": "AirflowTaskException",
        "error_message": "Task queue not found",
        "description": "Occurs when the task's queue is not recognized by the executor.",
        "first_steps": "Ensure the specified queue exists in the Airflow configuration. Review the executor settings to confirm it can process tasks from the specified queue.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/queues.html",
    },
    "AERR047": {
        "exception_type": "AirflowSchedulerException",
        "error_message": "Executor cannot retrieve task instance",
        "description": "Happens when the executor fails to fetch task instance details from the database.",
        "first_steps": "Verify the database connection and ensure the task instance details are present in the metadata database. Check the executor logs for any errors.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/task-instance.html#status",
    },
    "AERR048": {
        "exception_type": "AirflowWebServerException",
        "error_message": "Webserver connection refused",
        "description": "Occurs when the webserver process is not running or accessible.",
        "first_steps": "Check the webserver logs for errors. Restart the webserver and verify that it is running and accessible through the configured URL.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/webserver.html",
    },
    "AERR049": {
        "exception_type": "AirflowTaskException",
        "error_message": "Invalid return type from PythonOperator",
        "description": "Happens when a PythonOperator returns a value of an unexpected type.",
        "first_steps": "Ensure the Python function used in the PythonOperator returns the expected type. Review the function implementation for type correctness.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/python.html",
    },
    "AERR050": {
        "exception_type": "AirflowConfigException",
        "error_message": "Config error: executor not defined",
        "description": "Triggered when the Airflow configuration does not specify a valid executor.",
        "first_steps": "Review the `airflow.cfg` file and verify that the executor is correctly specified. Ensure that the specified executor is installed and properly configured.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/executors/index.html",
    },
    "AERR051": {
        "exception_type": "AirflowException",
        "error_message": "Error in task failure hook execution",
        "description": "Triggered when the failure hook defined for a task encounters an error.",
        "first_steps": "Check the failure hook configuration for errors. Review the task and hook logs to identify the cause of the failure and resolve any issues.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator.html#failure-hooks",
    },
    "AERR052": {
        "exception_type": "AirflowTemplateException",
        "error_message": "Failed to resolve template variable",
        "description": "Triggered when a task's templated field contains errors or undefined variables.",
        "first_steps": "Review the task templated fields for any errors or undefined variables. Ensure all variables are defined and passed correctly in the DAG.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/operators.html#templating",
    },
    "AERR053": {
        "exception_type": "AirflowSchedulerException",
        "error_message": "Scheduler process killed unexpectedly",
        "description": "Triggered when the scheduler process is terminated due to resource or system issues.",
        "first_steps": "Investigate the system logs for resource-related issues. Increase system resources or adjust scheduler configurations to prevent termination.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/scheduler.html",
    },
    "AERR054": {
        "exception_type": "AirflowTaskTimeout",
        "error_message": "Task failed with exit code 1",
        "description": "Occurs when a task script or subprocess exits with a non-zero code indicating failure.",
        "first_steps": "Check the task script or subprocess logs for the error code and cause of failure. Debug the script and address any underlying issues.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/bash.html",
    },
    "AERR055": {
        "exception_type": "AirflowDatabaseException",
        "error_message": "TaskInstance already exists in database",
        "description": "Occurs when a duplicate TaskInstance entry is created in the metadata database.",
        "first_steps": "Review task instance scheduling and ensure that duplicate entries are not being created. Investigate DAG scheduling logic for potential issues.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/metadata-database.html",
    },
    "AERR056": {
        "exception_type": "AirflowDatabaseException",
        "error_message": "Could not reach the database",
        "description": "Indicates connectivity issues with the metadata database, often due to misconfiguration.",
        "first_steps": "Verify the connection settings in `airflow.cfg` for the metadata database. Ensure that the database is accessible and network connectivity is working.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/metadata-database.html#troubleshooting",
    },
    "AERR057": {
        "exception_type": "AirflowExecutorException",
        "error_message": "Task stuck in 'deferred' state",
        "description": "Triggered when a task using deferrable operators remains in 'deferred' longer than expected.",
        "first_steps": "Review the deferrable operator configuration and execution logic. Ensure that the task is properly resumed and that there are no long delays in task deferral.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/deferrable.html",
    },
    "AERR058": {
        "exception_type": "AirflowException",
        "error_message": "Error loading custom operator",
        "description": "Indicates a problem in importing or defining a custom operator in the DAG.",
        "first_steps": "Check the custom operator import path and ensure it is available. Verify that the custom operator class is correctly defined and instantiated.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator.html#creating-custom-operators",
    },
    "AERR059": {
        "exception_type": "AirflowTriggerException",
        "error_message": "Trigger timeout for external task",
        "description": "Occurs when an ExternalTaskSensor exceeds its timeout waiting for an external task.",
        "first_steps": "Increase the timeout setting for the ExternalTaskSensor. Check if the external task is delayed and adjust the DAG dependencies accordingly.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/external-task.html",
    },
    "AERR060": {
        "exception_type": "AirflowDagImportException",
        "error_message": "DagBag import errors",
        "description": "Happens when the scheduler encounters issues loading DAG files into the DagBag.",
        "first_steps": "Check the DAG files for syntax or configuration errors. Inspect the DagBag loading process to ensure no invalid DAGs are being included.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/scheduler.html#dagbag",
    },
    "AERR061": {
        "exception_type": "AirflowDagNotFound",
        "error_message": "DAG not found in trigger DAG run",
        "description": "Triggered when the DAG specified in a TriggerDagRunOperator does not exist.",
        "first_steps": "Check the name of the target DAG in the TriggerDagRunOperator. Ensure that the DAG exists and is correctly spelled in the configuration.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/trigger-dag.html",
    },
    "AERR062": {
        "exception_type": "AirflowDagCycleException",
        "error_message": "Circular dependencies in DAG",
        "description": "Triggered when tasks in a DAG form a circular dependency loop.",
        "first_steps": "Review the task dependencies and remove any circular references. Modify the DAG structure to avoid infinite dependency loops.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html#task-dependencies",
    },
    "AERR063": {
        "exception_type": "AirflowException",
        "error_message": "Error in on_failure_callback for DAG",
        "description": "Occurs when the on_failure_callback for a DAG raises an exception.",
        "first_steps": "Check the on_failure_callback function for errors. Ensure it handles exceptions correctly and does not raise additional errors during task failure.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/advanced/alerts.html",
    },
    "AERR064": {
        "exception_type": "AirflowTriggerException",
        "error_message": "TriggerDagRunOperator failed",
        "description": "Happens when the TriggerDagRunOperator cannot trigger the specified target DAG.",
        "first_steps": "Verify the configuration of the TriggerDagRunOperator. Ensure the target DAG exists and the trigger parameters are correct.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/trigger-dag.html",
    },
    "AERR065": {
        "exception_type": "AirflowTaskException",
        "error_message": "DAG execution failed",
        "description": "Indicates that the overall execution of a DAG run failed due to errors in one or more tasks.",
        "first_steps": "Check the logs for each task to determine which task failed. Review task dependencies, configurations, and retries.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dag-run.html#status",
    },
    "AERR066": {
        "exception_type": "AirflowSchedulerException",
        "error_message": "Scheduler heartbeat failed",
        "description": "Occurs when the scheduler process stops sending heartbeats, often due to resource issues.",
        "first_steps": "Investigate the system resources, such as CPU and memory, and increase them if necessary. Restart the scheduler and monitor system performance.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/scheduler.html",
    },
    "AERR067": {
        "exception_type": "AirflowConfigException",
        "error_message": "Scheduler crashes when passing invalid value to argument in default_args",
        "description": "Occurs when default_args in a DAG contains an invalid or incompatible parameter.",
        "first_steps": "Review the `default_args` section in the DAG definition. Ensure all parameters are valid and compatible with the Airflow version in use.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html#default-args",
    },
    "AERR068": {
        "exception_type": "AirflowApiException",
        "error_message": "HTTP error while connecting to API",
        "description": "Occurs when Airflow encounters connectivity issues or invalid responses from an external API.",
        "first_steps": "Check the API connection settings and ensure that the external service is reachable. Verify that the API is returning valid responses.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/http.html",
    },
    "AERR069": {
        "exception_type": "AirflowSchedulerException",
        "error_message": "Scheduler backlog due to excessive retries",
        "description": "Happens when too many tasks are retried, overloading the scheduler.",
        "first_steps": "Adjust the task retry logic and retry limits. Review task logs for patterns that lead to excessive retries and optimize DAG logic.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/operator.html#retries",
    },
    "AERR070": {
        "exception_type": "AirflowException",
        "error_message": "DAG folder not found",
        "description": "Triggered when the directory specified for DAGs does not exist or is inaccessible.",
        "first_steps": "Ensure that the DAG directory exists and is accessible by the Airflow scheduler and webserver. Check directory permissions and paths.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/dags-directory.html",
    },
    "AERR071": {
        "exception_type": "AirflowException",
        "error_message": "Max active tasks for DAG exceeded",
        "description": "Triggered when the number of concurrent tasks for a DAG exceeds the configured limit.",
        "first_steps": "Increase the task concurrency settings in the DAG configuration or adjust the task dependencies to limit the number of concurrent tasks.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/scheduler.html#concurrency",
    },
    "AERR072": {
        "exception_type": "AirflowException",
        "error_message": "Cannot find DAG run in the database",
        "description": "Happens when the specified DAG run is missing or deleted from the metadata database.",
        "first_steps": "Verify the DAG run's existence in the metadata database. Ensure the run has not been manually deleted or corrupted.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dag-run.html",
    },
    "AERR073": {
        "exception_type": "AirflowException",
        "error_message": "Airflow CLI not recognized",
        "description": "Happens when the Airflow CLI command is not installed or available in the PATH.",
        "first_steps": "Ensure that Airflow is properly installed and that the CLI is accessible in the environment PATH. Reinstall or reconfigure Airflow if necessary.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/cli-and-commands.html",
    },
    "AERR074": {
        "exception_type": "AirflowDatabaseException",
        "error_message": "SQLAlchemy database connection error",
        "description": "Happens when the connection string for the metadata database is invalid or unreachable.",
        "first_steps": "Check the connection string in the Airflow configuration. Ensure the database is reachable and verify the credentials and network configuration.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/database-setup.html",
    },
    "AERR075": {
        "exception_type": "PermissionError",
        "error_message": "Permission denied for Airflow logs",
        "description": "Occurs when Airflow does not have the required permissions to read or write logs.",
        "first_steps": "Check the file permissions for the Airflow logs directory. Ensure that the user running Airflow has proper read and write access.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/logging.html",
    },
    "AERR076": {
        "exception_type": "AirflowException",
        "error_message": "Task marked as 'up for retry' without retries available",
        "description": "Happens when a task is incorrectly marked for retry but has exceeded its limit.",
        "first_steps": "Check the task's retry configuration in the DAG. Ensure that the retry count is properly set in the task's arguments and verify if retries are needed.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/operator.html#retries",
    },
    "AERR077": {
        "exception_type": "AirflowConfigException",
        "error_message": "Invalid section in airflow.cfg",
        "description": "Triggered when airflow.cfg contains an unrecognized configuration section.",
        "first_steps": "Review your airflow.cfg file to ensure that all sections are correctly defined and recognized. Consult the official Airflow configuration reference to verify your settings.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/configurations-ref.html",
    },
    "AERR078": {
        "exception_type": "AirflowException",
        "error_message": "Task dependencies are not met",
        "description": "Indicates a task cannot start due to upstream dependencies not being completed.",
        "first_steps": "Ensure that all upstream tasks have been successfully completed before the task is triggered. Review the task dependencies in your DAG to make sure they are properly defined.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/task-instance.html",
    },
    "AERR079": {
        "exception_type": "AirflowException",
        "error_message": "Task not found in serialized DAG",
        "description": "Occurs when the task referenced is missing from the serialized DAG in the database.",
        "first_steps": "Check your DAG serialization settings and verify that all tasks are properly serialized. Ensure that the task is defined correctly in the DAG file.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html#dag-serialization",
    },
    "AERR080": {
        "exception_type": "AirflowException",
        "error_message": "Worker node not available",
        "description": "Triggered when an executor cannot find a suitable worker to run a task.",
        "first_steps": "Check if there are any worker nodes available and verify if the executor configuration is correct. Ensure the workers are running and properly configured in the Airflow setup.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/executors/index.html",
    },
    "AERR081": {
        "exception_type": "ModuleNotFoundError",
        "error_message": "Python dependency not installed",
        "description": "Occurs when a Python package required by a DAG is missing.",
        "first_steps": "Verify that all required Python packages are installed in the environment where Airflow is running. Install any missing dependencies using `pip` or a virtual environment manager.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/python.html#python-packages",
    },
    "AERR082": {
        "exception_type": "AirflowExecutorException",
        "error_message": "Celery task not acknowledged",
        "description": "Occurs when a Celery task is not acknowledged by a worker.",
        "first_steps": "Check the Celery worker logs to determine why the task was not acknowledged. Ensure that Celery is properly configured and running in your Airflow setup.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/executors/celery.html",
    },
    "AERR083": {
        "exception_type": "AirflowTaskTimeout",
        "error_message": "Task duration exceeds timeout",
        "description": "Happens when a task exceeds its specified execution timeout.",
        "first_steps": "Review the task's execution timeout setting. If necessary, increase the timeout or optimize the task to ensure it completes within the allowed duration.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/operator.html#timeouts",
    },
    "AERR084": {
        "exception_type": "AirflowException",
        "error_message": "Error migrating database to Airflow version 2.9.3",
        "description": "Indicates issues during metadata database migration, often due to schema mismatches.",
        "first_steps": "Check the database schema and migration logs for errors. You may need to run manual database migrations or troubleshoot database connectivity and compatibility issues.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/database-migrations.html",
    },
    "AERR085": {
        "exception_type": "AirflowException",
        "error_message": "Error writing metrics to statsd",
        "description": "Occurs when Airflow fails to send metrics data to the configured statsd server.",
        "first_steps": "Verify the connection settings to your statsd server. Ensure that the statsd server is reachable and properly configured in Airflow's settings.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/metrics.html",
    },
    "AERR086": {
        "exception_type": "AirflowException",
        "error_message": "DAG import timeout",
        "description": "Occurs when DAG files take too long to parse, possibly due to large files or inefficient code.",
        "first_steps": "Review your DAG files to identify any large or inefficient code. Optimize DAG parsing and consider splitting large DAGs into smaller ones to improve performance.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/scheduler.html#dag-parsing",
    },
    "AERR087": {
        "exception_type": "AirflowTemplateException",
        "error_message": "Invalid template in BashOperator command",
        "description": "Happens when the command template in BashOperator contains errors.",
        "first_steps": "Check the BashOperator template for syntax errors. Ensure all placeholders and variables are correctly defined and are available in the context of the task.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/bash.html",
    },
    "AERR088": {
        "exception_type": "AirflowDagCycleException",
        "error_message": "Multiple DAGs with same ID",
        "description": "Triggered when two or more DAGs have the same ID, causing conflicts.",
        "first_steps": "Ensure that each DAG has a unique DAG ID. Review your DAG files to identify any duplicate DAG IDs and resolve the conflict.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html#dag-id",
    },
    "AERR089": {
        "exception_type": "AttributeError",
        "error_message": "AttributeError in PythonOperator",
        "description": "Occurs when the Python callable in a PythonOperator is improperly defined or missing required attributes.",
        "first_steps": "Check the Python callable in your PythonOperator. Ensure that all required arguments and attributes are defined and passed correctly.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/python.html",
    },
    "AERR090": {
        "exception_type": "AirflowException",
        "error_message": "Error in callback execution for TaskInstance",
        "description": "Occurs when a failure callback defined for a task raises an error.",
        "first_steps": "Review the callback function for errors. Ensure that the function is correctly defined and handles exceptions as expected.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/advanced/alerts.html",
    },
    "AERR091": {
        "exception_type": "AirflowTaskTimeout",
        "error_message": "Operator execution exceeded SLA",
        "description": "Happens when a task operator runs longer than its Service Level Agreement (SLA).",
        "first_steps": "Review the task's execution time and optimize the code to ensure it completes within the specified SLA. Adjust the SLA if necessary to account for task duration.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/operator.html#sla",
    },
    "AERR092": {
        "exception_type": "AirflowDagNotFound",
        "error_message": "DAG not found in scheduler",
        "description": "Occurs when a DAG file is not loaded into the scheduler, often due to parsing errors or missing files.",
        "first_steps": "Check for errors in the DAG parsing logs. Ensure that the DAG file exists in the DAGs folder and is properly formatted.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/scheduler.html#dagbag",
    },
    "AERR093": {
        "exception_type": "AirflowException",
        "error_message": "Error in email notification for task",
        "description": "Triggered when an email notification for a task failure cannot be sent.",
        "first_steps": "Verify the email configuration in Airflow. Check if the SMTP server is correctly configured and reachable from the Airflow instance.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/advanced/alerts.html#email-alerts",
    },
    "AERR094": {
        "exception_type": "AirflowWebServerException",
        "error_message": "Airflow webserver won't start",
        "description": "Happens when the webserver process fails, often due to misconfiguration or missing dependencies.",
        "first_steps": "Check the webserver logs for errors. Ensure that all required dependencies are installed and the configuration is correct.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/webserver.html",
    },
    "AERR095": {
        "exception_type": "ModuleNotFoundError",
        "error_message": "No module named '...' in DAG file",
        "description": "Occurs when the DAG imports a Python module that is not installed or available.",
        "first_steps": "Install the missing Python module using pip or ensure the module is available in the environment where Airflow is running.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/python.html",
    },
    "AERR096": {
        "exception_type": "AirflowTemplateException",
        "error_message": "Missing template field in operator",
        "description": "Happens when a required templated field is not defined for a task operator.",
        "first_steps": "Review the task operator and ensure all required templated fields are defined. Add any missing fields to the operator's parameters.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/operators.html#templating",
    },
    "AERR097": {
        "exception_type": "AirflowException",
        "error_message": "Error syncing DAGs to remote storage",
        "description": "Happens when DAG files fail to sync with a remote storage backend like S3 or GCS.",
        "first_steps": "Verify the connection to the remote storage backend. Ensure that the correct credentials are configured and that the storage service is accessible.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/storage.html#remote-storage-backends",
    },
    "AERR098": {
        "exception_type": "AirflowTaskTimeout",
        "error_message": "Subprocess in task exceeded timeout",
        "description": "Happens when a subprocess spawned by a task runs longer than its allowed time.",
        "first_steps": "Review the subprocess configuration and ensure it completes within the task's timeout. If needed, increase the timeout or optimize the subprocess execution.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/operator.html#timeouts",
    },
    "AERR099": {
        "exception_type": "AirflowDatabaseException",
        "error_message": "Inconsistent database schema",
        "description": "Occurs when the metadata database schema is outdated or corrupted.",
        "first_steps": "Check the database schema and run any necessary migrations. Ensure the database is in sync with the current Airflow version.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/administration/database-setup.html",
    },
    "AERR100": {
        "exception_type": "AirflowException",
        "error_message": "Invalid DAG structure",
        "description": "Triggered when a DAG's dependencies or attributes are incorrectly defined.",
        "first_steps": "Review the DAG structure for errors. Ensure that all dependencies are correctly defined and that no circular dependencies exist.",
        "documentation": "https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html",
    },
}
