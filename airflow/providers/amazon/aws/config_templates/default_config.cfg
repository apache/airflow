#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# This is the template for Airflow's default configuration. When Airflow is
# imported, it looks for a configuration file at $AIRFLOW_HOME/airflow.cfg. If
# it doesn't exist, Airflow uses this template to generate it by replacing
# variables in curly braces with their global values from configuration.py.

# Users should not modify this file; they should customize the generated
# airflow.cfg instead.


# ----------------------- TEMPLATE BEGINS HERE -----------------------

[aws_ecs]

# This section only applies if you are using the AwsEcsExecutor in
# Airflow's ``[core]`` configuration.
# For more information on any of these execution parameters, see the link below:
# https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs/client/run_task.html
# For boto3 credential management, see
# https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
# The name of the AWS Region where Amazon ECS is configured. Required.
# Example: region = us-east-1
# region =

# Name of Amazon ECS Cluster. Required.
# cluster =

# Name of registered Airflow container within your AWS cluster. This container will
# receive an airflow CLI command as an additional parameter to its entrypoint.
# For more info see url to Boto3 docs above. Required.
# container_name =

# Name of AWS Task Definition. For more info see url to Boto3 docs above.
# Example: task_definition = us-east-1
# task_definition =

# Launch type can either be 'FARGATE' OR 'EC2'. For more info see url to Boto3 docs above.
platform_version = LATEST
launch_type = FARGATE

# Assign public ip. For more info see url to Boto3 docs above.
# assign_public_ip =

# Security group ids for task to run in (comma-separated). For more info see url to Boto3 docs above.
# security_groups =

# Subnets for task to run in (comma-separated). For more info see url to Boto3 docs above.
# Example: subnets = subnet-XXXXXXXX,subnet-YYYYYYYY
# subnets =

# This is the default configuration for calling the ECS `run_task` function API (see url above).
# To change the parameters used to run a task in FARGATE or EC2, the user can overwrite the path to
# specify another jinja-templated JSON. More documentation can be found in the DEFAULT_RUN_TASK_KWARGS
# variable in the AWS ECS Executor.
# Example: run_task_template = path.to.your.python_package.variable_name
run_task_template = airflow.providers.amazon.aws.executors.ecs.ecs_executor_conf.DEFAULT_AWS_ECS_CONFIG
