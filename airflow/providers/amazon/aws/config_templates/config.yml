# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
---
batch:
  description: |
    This section only applies if you are using the BatchExecutor in
    Airflow's ``[core]`` configuration.
    For more information on any of these execution parameters, see the link below:
    https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/batch/client/submit_job.html
    For boto3 credential management, see
    https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
  options:
    region:
      description: |
        The name of the AWS Region where AWS Batch is configured.
      version_added: 2.5.1
      type: string
      example: us-east-1
      default: ~
    job_name:
      description: |
        The name of the Airflow Job configured in AWS Batch.
      version_added: 2.5.1
      type: string
      example: airflow-job-name
      default: ~
    job_queue:
      description: |
        The job queue where the Airflow job is submitted. You can specify either the name or the Amazon
        Resource Name (ARN) of the queue.
      version_added: 2.5.1
      type: string
      example: airflow-job-name or airflow-job-name:2
      default: ~
    job_definition:
      description: |
        The name of the Airflow Job Queue configured in AWS Batch;
        optionally includes revision number.
      version_added: 2.5.1
      type: string
      example:
      default: ~
    submit_job_kwargs:
      description: |
        Points to a Python dictionary which provides **kwargs for boto3's Batch submit_job API. Most
        implementations can leave this to the default value. This API is provided for maximum extensibility
        for submitting Airflow Jobs on AWS Batch (i.e: retry strategy, timeouts, etc). More documentation
        can be found in the "Extensibility" section of the AWS Executors Readme.
      version_added: 2.5.1
      type: string
      example: path.to.your.python_package.variable_name
      default: airflow.providers.amazon.aws.executors.batch_conf.BATCH_SUBMIT_JOB_KWARGS

aws_ecs:
  description: |
    This section only applies if you are using the AwsEcsExecutor in
    Airflow's ``[core]`` configuration.
    For more information on any of these execution parameters, see the link below:
    https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ecs/client/run_task.html
    For boto3 credential management, see
    https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
  options:
    region:
      description: |
        The name of the AWS Region where AWS ECS/Fargate is configured.
      version_added: 2.5.1
      type: string
      example: us-east-1
      default: ~
    cluster:
      description: |
       Name of AWS ECS or Fargate cluster.
      version_added: 2.5.1
      type: string
      example: ~
      default: ~
    container_name:
      description: |
        Name of registered Airflow container within your AWS cluster. This container will
        receive an airflow CLI command as an additional parameter to its entrypoint.
        For more info see url to Boto3 docs above.
      version_added: 2.5.1
      type: string
      example: ~
      default: ~
    task_definition:
      description: |
        Name of AWS Task Definition. For more info see url to Boto3 docs above.
      version_added: 2.5.1
      type: string
      example: us-east-1
      default: ~
    platform_version:
      description: |
        Launch type can either be 'FARGATE' OR 'EC2'. For more info see url to Boto3 docs above.
      version_added: 2.5.1
      type: string
      example: ~
      default: LATEST
    launch_type:
      description: |
      version_added: 2.5.1
      type: string
      example: ~
      default: FARGATE
    assign_public_ip:
      description: |
        Assign public ip. For more info see url to Boto3 docs above.
      version_added: 2.5.1
      type: string
      example: ~
      default: ~
    security_groups:
      description: |
        Security group ids for task to run in (comma-separated). For more info see url to Boto3 docs above.
      version_added: 2.5.1
      type: string
      example:
      default: ~
    subnets:
      description: |
        Subnets for task to run in (comma-separated). For more info see url to Boto3 docs above.
      version_added: 2.5.1
      type: string
      example: subnet-XXXXXXXX,subnet-YYYYYYYY
      default: ~
    run_task_template:
      description: |
        This is the default configuration for calling the ECS `run_task` function API (see url above).
        To change the parameters used to run a task in FARGATE or ECS, the user can overwrite the path to
        specify another jinja-templated JSON. More documentation can be found in the DEFAULT_RUN_TASK_KWARGS
        variable in the AWS ECS Executor.
      version_added: 2.5.1
      type: string
      example: path.to.your.python_package.variable_name
      default: airflow.providers.amazon.aws.executors.ecs_fargate_conf.DEFAULT_AWS_ECS_CONFIG
